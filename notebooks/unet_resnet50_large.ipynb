{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net with ResNet50 Encoder for Golf Course Segmentation\n",
    "# Image size: 832x512, Classes: 6\n",
    "\n",
    "# Check environment\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running on Google Colab\")\n",
    "    !pip install -q kagglehub\n",
    "else:\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Configuration\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(f\"GPU configured: {len(gpus)} device(s)\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu}\")\n",
    "else:\n",
    "    print(\"No GPU detected, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset (works on both Colab and local)\n",
    "# Note: You may need to authenticate with Kaggle on first run\n",
    "# For Colab: upload kaggle.json or use kagglehub.login()\n",
    "\n",
    "dataset_path = kagglehub.dataset_download('jacotaco/danish-golf-courses-orthophotos')\n",
    "print(f\"Dataset path: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 2  # Reduce to 1 if OOM on Colab\n",
    "IMAGE_SIZE = (512, 832)  # Height x Width\n",
    "IN_CHANNELS = 3\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 6  # Background, Fairway, Green, Tee, Bunker, Water\n",
    "MAX_EPOCHS = 10\n",
    "AUGMENTATION_PROBABILITY = 0.25\n",
    "\n",
    "# Dataset paths\n",
    "base_path = dataset_path\n",
    "IMAGES_DIR = os.path.join(base_path, '1. orthophotos')\n",
    "SEGMASKS_DIR = os.path.join(base_path, '2. segmentation masks')\n",
    "LABELMASKS_DIR = os.path.join(base_path, '3. class masks')\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = '/content/output' if IN_COLAB else './output'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview sample\n",
    "orthophoto_list = os.listdir(IMAGES_DIR)\n",
    "print(f\"Total images: {len(orthophoto_list)}\")\n",
    "\n",
    "idx = 5\n",
    "golf_image = Image.open(os.path.join(IMAGES_DIR, orthophoto_list[idx]))\n",
    "golf_segmask = Image.open(os.path.join(SEGMASKS_DIR, orthophoto_list[idx].replace(\".jpg\", \".png\")))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].set_title('Orthophoto')\n",
    "axes[1].set_title('Segmentation Mask')\n",
    "axes[0].imshow(golf_image)\n",
    "axes[1].imshow(golf_segmask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path, mask_path):\n",
    "    \"\"\"Load and preprocess image and mask pair.\"\"\"\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, IMAGE_SIZE, method='nearest')\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask = tf.squeeze(mask, axis=-1)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def augment_image_and_mask(image, mask):\n",
    "    \"\"\"Apply synchronized augmentation to image and mask.\"\"\"\n",
    "    def apply_augmentation():\n",
    "        mask_expanded = tf.expand_dims(mask, axis=-1)\n",
    "        combined = tf.concat([image, mask_expanded], axis=-1)\n",
    "        combined = tf.image.random_flip_left_right(combined)\n",
    "        aug_image = combined[:, :, :3]\n",
    "        aug_mask = combined[:, :, 3]\n",
    "        aug_image = tf.image.random_brightness(aug_image, 0.1)\n",
    "        aug_image = tf.image.random_contrast(aug_image, 0.9, 1.1)\n",
    "        aug_image = tf.clip_by_value(aug_image, 0.0, 1.0)\n",
    "        return tf.cast(aug_image, tf.float32), aug_mask\n",
    "\n",
    "    def keep_original():\n",
    "        return tf.cast(image, tf.float32), mask\n",
    "\n",
    "    should_augment = tf.random.uniform([]) < AUGMENTATION_PROBABILITY\n",
    "    return tf.cond(should_augment, apply_augmentation, keep_original)\n",
    "\n",
    "\n",
    "def create_dataset(images_dir, labelmasks_dir, shuffle=True):\n",
    "    \"\"\"Create TensorFlow dataset from directories.\"\"\"\n",
    "    image_filenames = sorted(os.listdir(images_dir))\n",
    "    image_paths = [os.path.join(images_dir, fname) for fname in image_filenames]\n",
    "    mask_paths = [os.path.join(labelmasks_dir, fname.replace('.jpg', '.png')) for fname in image_filenames]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths), seed=42)\n",
    "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset, len(image_paths)\n",
    "\n",
    "\n",
    "def prepare_datasets():\n",
    "    \"\"\"Prepare train/val/test datasets with 70/20/10 split.\"\"\"\n",
    "    full_dataset, total_size = create_dataset(IMAGES_DIR, LABELMASKS_DIR, shuffle=True)\n",
    "\n",
    "    train_size = int(0.7 * total_size)\n",
    "    val_size = int(0.2 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    print(f\"Split: {train_size} train, {val_size} val, {test_size} test\")\n",
    "\n",
    "    train_ds = full_dataset.take(train_size)\n",
    "    remaining = full_dataset.skip(train_size)\n",
    "    val_ds = remaining.take(val_size)\n",
    "    test_ds = remaining.skip(val_size)\n",
    "\n",
    "    train_ds = train_ds.map(augment_image_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_resnet50(input_shape=(512, 832, 3), num_classes=6):\n",
    "    \"\"\"U-Net with ResNet50 encoder (ImageNet pretrained).\"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder: ResNet50\n",
    "    base_model = keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=inputs\n",
    "    )\n",
    "\n",
    "    # Skip connections at different resolutions\n",
    "    skip_layer_names = [\n",
    "        'conv1_relu',        # 1/2\n",
    "        'conv2_block3_out',  # 1/4\n",
    "        'conv3_block4_out',  # 1/8\n",
    "        'conv4_block6_out',  # 1/16\n",
    "    ]\n",
    "    skip_connections = [base_model.get_layer(name).output for name in skip_layer_names]\n",
    "    bottleneck = base_model.get_layer('conv5_block3_out').output  # 1/32\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Conv2DTranspose(512, kernel_size=2, strides=2, padding='same')(bottleneck)\n",
    "    x = layers.Concatenate()([x, skip_connections[3]])\n",
    "    x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(256, kernel_size=2, strides=2, padding='same')(x)\n",
    "    x = layers.Concatenate()([x, skip_connections[2]])\n",
    "    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=2, strides=2, padding='same')(x)\n",
    "    x = layers.Concatenate()([x, skip_connections[1]])\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, kernel_size=2, strides=2, padding='same')(x)\n",
    "    x = layers.Concatenate()([x, skip_connections[0]])\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(32, kernel_size=2, strides=2, padding='same')(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    # Output\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, padding='same', dtype='float32')(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name='UNet_ResNet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile model\n",
    "model = build_unet_resnet50(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=LEARNING_RATE),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_ds, val_ds, test_ds = prepare_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(OUTPUT_DIR, 'best_unet_resnet50.keras'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=MAX_EPOCHS,\n",
    "    callbacks=callback_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class colors for visualization\n",
    "CLASS_COLORS = np.array([\n",
    "    [0, 0, 0],        # Background\n",
    "    [0, 140, 0],      # Fairway\n",
    "    [0, 255, 0],      # Green\n",
    "    [255, 0, 0],      # Tee\n",
    "    [217, 230, 122],  # Bunker\n",
    "    [7, 15, 247]      # Water\n",
    "], dtype=np.float32) / 255.0\n",
    "\n",
    "CLASS_NAMES = ['Background', 'Fairway', 'Green', 'Tee', 'Bunker', 'Water']\n",
    "\n",
    "\n",
    "def mask_to_rgb(mask):\n",
    "    \"\"\"Convert class mask to RGB.\"\"\"\n",
    "    h, w = mask.shape\n",
    "    rgb_mask = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    for class_id in range(NUM_CLASSES):\n",
    "        rgb_mask[mask == class_id] = CLASS_COLORS[class_id]\n",
    "    return rgb_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "for images, masks in test_ds.take(3):\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    pred_masks = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    for i in range(min(2, images.shape[0])):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].imshow(images[i].numpy())\n",
    "        axes[0].set_title('Input')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(mask_to_rgb(masks[i].numpy().astype(np.int32)))\n",
    "        axes[1].set_title('Ground Truth')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(mask_to_rgb(pred_masks[i]))\n",
    "        axes[2].set_title('Prediction')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(os.path.join(OUTPUT_DIR, 'final_unet_resnet50.keras'))\n",
    "print(f\"Model saved to {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Val')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Val')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model from Colab\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    files.download(os.path.join(OUTPUT_DIR, 'final_unet_resnet50.keras'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
